{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "num_samples,num_features = data.shape[0],data.shape[1]\n",
    "print(f'num_samples,num_features = {(num_samples,num_features)}')\n",
    "indices = np.arange(num_samples)\n",
    "X_train, X_test, y_train, y_test,train_indices,test_indices = train_test_split(data, labels,indices, test_size=0.6, random_state=42)\n",
    "train_indices = np.arange(1,num_samples,4)\n",
    "test_indices = np.arange(0,num_samples,4)\n",
    "print(f'train_indices ={train_indices.shape},test_indices ={test_indices.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy.random import randint\n",
    "from numpy.random import rand\n",
    "\n",
    "\n",
    "def select_features(elem,features):\n",
    "    selected_elem = np.where(elem==1)[0]\n",
    "    selected_features = features[:,selected_elem]\n",
    "    return selected_features\n",
    "\n",
    "def classification_accuracy(labels,preds):\n",
    "    correct = np.where(labels == preds)[0]\n",
    "    accuracy = correct.shape[0]/labels.shape[0]\n",
    "    return accuracy\n",
    "\n",
    "def objective(pop,data,labels,train_ind,test_ind):\n",
    "    accuracies = np.zeros(pop.shape[0])\n",
    "    idx= 0\n",
    "    for elem in pop:\n",
    "        selected_features = select_features(elem,data)\n",
    "        train_data = selected_features[train_ind,:]\n",
    "        test_data = selected_features[test_ind,:]\n",
    "        if train_data.shape[0]==0 or train_data.shape[1]==0 or test_data.shape[0]==0 or test_data.shape[1]==0:\n",
    "            continue\n",
    "        train_labels = labels[train_indices]\n",
    "        test_labels = labels[test_indices]\n",
    "        LR_classifier = LR(random_state=0)\n",
    "        LR_classifier.fit(X=train_data, y=train_labels)\n",
    "        predictions = LR_classifier.predict(test_data)\n",
    "        accuracies[idx] = classification_accuracy(test_labels, predictions)\n",
    "        idx = idx + 1\n",
    "    return accuracies\n",
    "\n",
    "def parent_selection(pop,n_pop,scores,k=3):\n",
    "    selected = []\n",
    "    for _ in range(n_pop):\n",
    "        idx = randint(len(pop))\n",
    "        for ix in randint(0, len(pop),k-1):\n",
    "            # check if better (e.g. perform a tournament)\n",
    "            if scores[ix] < scores[idx]:\n",
    "                idx = ix\n",
    "        selected.append(pop[idx])\n",
    "    return selected\n",
    "\n",
    "def crossover(p1,p2,r_cross):\n",
    "    c1 = p1.copy()\n",
    "    c2 = p2.copy()\n",
    "    if rand() < r_cross:\n",
    "        pt = randint(1, len(p1)-2)\n",
    "        c1 = list(p1[:pt])+list(p2[pt:])\n",
    "        c2 = list(p2[:pt])+list(p1[pt:])\n",
    "    return [np.array(c1), np.array(c2)]\n",
    "\n",
    "def mutation(bitstring, r_mut):\n",
    "    for i in range(len(bitstring)):\n",
    "        # check for a mutation\n",
    "        if rand() < r_mut:\n",
    "            # flip the bit\n",
    "            bitstring[i] = 1 - bitstring[i]\n",
    "    return bitstring\n",
    "\n",
    "def get_children(selected_parents,n_pop,r_cross,r_mut):\n",
    "    children = []\n",
    "    for i in range(0, n_pop, 2):\n",
    "        p1, p2 = selected_parents[i], selected_parents[i+1]\n",
    "        for c in crossover(p1, p2, r_cross):\n",
    "            mutation(c, r_mut)\n",
    "            children.append(c)\n",
    "    return np.array(children)\n",
    "\n",
    "def genetic_algorithm(epochs,data,labels,train_indices,test_indices):\n",
    "    pop_size = 10\n",
    "    k = 4\n",
    "    r_cross = 0.9\n",
    "    r_mut = 1/pop_size\n",
    "    pop_shape = (pop_size, num_features)\n",
    "    #initial population\n",
    "    new_population = np.random.randint(low=0, high=2, size=pop_shape)\n",
    "    best_outputs = []\n",
    "    num_generations = epochs\n",
    "    for gen in range(num_generations):\n",
    "        #measure fitness of each member in population\n",
    "        scores = objective(new_population, data, labels, train_indices, test_indices)\n",
    "        \n",
    "        #print current best in population\n",
    "        best_outputs.append(np.max(scores))\n",
    "        print(f\"Gen: {gen} => Best result : {best_outputs[-1]}\")\n",
    "\n",
    "        #Select parent in current population to generate children for next generation\n",
    "        selected = parent_selection(new_population,pop_size,scores)\n",
    "        \n",
    "        #Get children of parents\n",
    "        children = get_children(selected,pop_size,r_cross,r_mut)\n",
    "        \n",
    "        #replace old population\n",
    "        new_population = children\n",
    "    \n",
    "    best_outputs.append(np.max(scores))\n",
    "    print(f\"Gen: {gen} => Best result : {best_outputs[-1]}\")\n",
    "\n",
    "    # Getting the best solution after iterating finishing all generations.\n",
    "    # At first, the fitness is calculated for each solution in the final generation.\n",
    "    scores = objective(new_population, data, labels, train_indices, test_indices)\n",
    "    # Then return the index of that solution corresponding to the best fitness.\n",
    "    best_match_idx = np.where(scores == np.max(scores))[0]\n",
    "    best_match_idx = best_match_idx[0]\n",
    "    print(f'np.max(scores) ={np.max(scores)}')\n",
    "    best_solution = new_population[best_match_idx, :]\n",
    "    best_solution_indices = np.where(best_solution == 1)[0]\n",
    "    best_solution_num_elements = best_solution_indices.shape[0]\n",
    "    best_solution_fitness = scores[best_match_idx]\n",
    "\n",
    "    print(\"best_match_idx : \", best_match_idx)\n",
    "    print(\"best_solution : \", best_solution)\n",
    "    print(\"Selected indices : \", best_solution_indices)\n",
    "    print(\"Number of selected elements : \", best_solution_num_elements)\n",
    "    print(\"Best solution fitness : \", best_solution_fitness)\n",
    "\n",
    "    plt.plot(best_outputs)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Fitness\")\n",
    "    plt.show()\n",
    "\n",
    "genetic_algorithm(100,data,labels,train_indices,test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
